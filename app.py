import gradio as gr
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
import torch

# Cargar modelo y tokenizer de CodeT5
tokenizer = AutoTokenizer.from_pretrained("Salesforce/codet5-base")
model = AutoModelForSeq2SeqLM.from_pretrained("Salesforce/codet5-base")

# Funci√≥n para generar explicaci√≥n del c√≥digo con CodeT5
def analizar_codigo(codigo):
    errores = "‚ö†Ô∏è No se realiz√≥ an√°lisis de sintaxis (solo compatible con Python)."
    try:
        # Preparamos el prompt para explicaci√≥n (puedes ajustar el prompt seg√∫n la tarea)
        prompt = f"Explain this JavaScript code:\n{codigo}\n"
        inputs = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=512)
        with torch.no_grad():
            summary_ids = model.generate(
                inputs.input_ids,
                max_length=128,
                num_beams=4,
                early_stopping=True
            )
        explicacion = tokenizer.decode(summary_ids[0], skip_special_tokens=True)
    except Exception as e:
        explicacion = f"‚ùå Error al analizar el c√≥digo: {str(e)}"
    return errores, explicacion

# Interfaz con Gradio
demo = gr.Interface(
    fn=analizar_codigo,
    inputs=gr.Textbox(lines=15, label="Pega tu c√≥digo JavaScript aqu√≠"),
    outputs=[
        gr.Textbox(label="Estado de la sintaxis"),
        gr.Textbox(label="Explicaci√≥n generada por CodeT5")
    ],
    title="üîç Explicador de c√≥digo JavaScript con CodeT5",
    description=(
        "Este Space utiliza CodeT5 para generar explicaciones autom√°ticas de tu c√≥digo JavaScript. "
        "No se realiza an√°lisis de sintaxis ni generaci√≥n textual autom√°tica."
    )
)

demo.launch()
